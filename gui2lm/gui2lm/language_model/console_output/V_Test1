/Users/davis/PycharmProjects/LmForGuiGeneration/venv/lib/python3.8/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.12.2 when it was built against 1.12.1, this may cause problems
  _warn(("h5py is running against HDF5 {0} when it was built against {1}, "
Enter Folder/Model Name: This is a TEST run
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 embedding (Embedding)       (None, 87, 8)             152

 dropout (Dropout)           (None, 87, 8)             0

 lstm (LSTM)                 (None, 64)                18688

 dropout_1 (Dropout)         (None, 64)                0

 dense (Dense)               (None, 19)                1235

=================================================================
Total params: 20,075
Trainable params: 20,075
Non-trainable params: 0
_________________________________________________________________
None
Nr. Training Sampels: 18902
Training Data Prepared
Nr. Validation Sampels: 3572
Validation Data Prepared

Search: Running Trial #1

Value             |Best Value So Far |Hyperparameter
8                 |?                 |embedding_dim
64                |?                 |num_of_neurons
0                 |?                 |num_of_layers
0.01              |?                 |learning_rate
2                 |?                 |tuner/epochs
0                 |?                 |tuner/initial_epoch
0                 |?                 |tuner/bracket
0                 |?                 |tuner/round

Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 embedding (Embedding)       (None, 87, 8)             152

 dropout (Dropout)           (None, 87, 8)             0

 lstm (LSTM)                 (None, 64)                18688

 dropout_1 (Dropout)         (None, 64)                0

 dense (Dense)               (None, 19)                1235

=================================================================
Total params: 20,075
Trainable params: 20,075
Non-trainable params: 0
_________________________________________________________________
None
2022-06-02 11:11:52.293394: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz
Epoch 1/2

148/148 [==============================] - 15s 79ms/step - loss: 6.3148 - accuracy: 0.5542 - val_loss: 3.8120 - val_accuracy: 0.6934
Epoch 2/2

148/148 [==============================] - 11s 77ms/step - loss: 3.6074 - accuracy: 0.6837 - val_loss: 3.2059 - val_accuracy: 0.7167


Trial 1 Complete [00h 00m 27s]
val_loss: 3.2059481143951416

Best val_loss So Far: 3.2059481143951416
Total elapsed time: 00h 00m 27s

Search: Running Trial #2

Value             |Best Value So Far |Hyperparameter
8                 |8                 |embedding_dim
64                |64                |num_of_neurons
0                 |0                 |num_of_layers
0.001             |0.01              |learning_rate
2                 |2                 |tuner/epochs
0                 |0                 |tuner/initial_epoch
0                 |0                 |tuner/bracket
0                 |0                 |tuner/round

Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 embedding (Embedding)       (None, 87, 8)             152

 dropout (Dropout)           (None, 87, 8)             0

 lstm (LSTM)                 (None, 64)                18688

 dropout_1 (Dropout)         (None, 64)                0

 dense (Dense)               (None, 19)                1235

=================================================================
Total params: 20,075
Trainable params: 20,075
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/2

148/148 [==============================] - 15s 79ms/step - loss: 11.0373 - accuracy: 0.4097 - val_loss: 10.0650 - val_accuracy: 0.3894
Epoch 2/2

148/148 [==============================] - 11s 74ms/step - loss: 8.9019 - accuracy: 0.4230 - val_loss: 8.1444 - val_accuracy: 0.4351


Trial 2 Complete [00h 00m 26s]
val_loss: 8.144418716430664

Best val_loss So Far: 3.2059481143951416
Total elapsed time: 00h 00m 53s

        The hyperparameter search is complete.
        Embedding dimension: 8 .
        Number of neurons: 64
        Number of layers:1
        Learning rate:0.01

Model: "sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 embedding_1 (Embedding)     (None, 87, 8)             152

 dropout_2 (Dropout)         (None, 87, 8)             0

 lstm_1 (LSTM)               (None, 64)                18688

 dropout_3 (Dropout)         (None, 64)                0

 dense_1 (Dense)             (None, 19)                1235

=================================================================
Total params: 20,075
Trainable params: 20,075
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/2

148/148 [==============================] - 16s 80ms/step - loss: 6.5354 - accuracy: 0.5626 - val_loss: 3.8235 - val_accuracy: 0.6934
Epoch 2/2

148/148 [==============================] - 11s 74ms/step - loss: 3.7322 - accuracy: 0.6970 - val_loss: 3.3608 - val_accuracy: 0.7074
Best epoch: 2
Model: "sequential_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 embedding_2 (Embedding)     (None, 87, 8)             152

 dropout_4 (Dropout)         (None, 87, 8)             0

 lstm_2 (LSTM)               (None, 64)                18688

 dropout_5 (Dropout)         (None, 64)                0

 dense_2 (Dense)             (None, 19)                1235

=================================================================
Total params: 20,075
Trainable params: 20,075
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/2

148/148 [==============================] - 16s 80ms/step - loss: 7.2381 - accuracy: 0.5426 - val_loss: 4.5952 - val_accuracy: 0.6761
Epoch 2/2

148/148 [==============================] - 11s 76ms/step - loss: 3.8864 - accuracy: 0.6848 - val_loss: 3.4784 - val_accuracy: 0.6926
Model Completed
Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1  Created
Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1/forced/  Created
Model: "sequential_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 embedding_3 (Embedding)     (None, 87, 8)             152

 dropout_6 (Dropout)         (None, 87, 8)             0

 lstm_3 (LSTM)               (None, 64)                18688

 dropout_7 (Dropout)         (None, 64)                0

 dense_3 (Dense)             (None, 19)                1235

=================================================================
Total params: 20,075
Trainable params: 20,075
Non-trainable params: 0
_________________________________________________________________
None

...Diversity: 0.2
...Forced teaching with Sentence: "< 0 6&B 0 | 0 1&2&B 0 | 0 1 0 | 1 4&5 4 >"

...Sentence :  < 0 6&B 0 | 0 1&2&B 0 | 0 1 0 | 1 4&5 4 >
...Generated:  < 0 1 7 0 | 0 0 2 3 0 | 1 0 0 | 0 1 4 0


...Diversity: 0.5
...Forced teaching with Sentence: "< 0 6&B 0 | 0 1&2&B 0 | 0 1 0 | 1 4&5 4 >"

...Sentence :  < 0 6&B 0 | 0 1&2&B 0 | 0 1 0 | 1 4&5 4 >
...Generated:  < 0 0 4 0 > 0 5 3 6 2 | 2 7 0 | 0&1 3 0


...Diversity: 1.0
...Forced teaching with Sentence: "< 0 6&B 0 | 0 1&2&B 0 | 0 1 0 | 1 4&5 4 >"

...Sentence :  < 0 6&B 0 | 0 1&2&B 0 | 0 1 0 | 1 4&5 4 >
...Generated:  < 2 2 580 | 8 3 5 8 0 | 0 002 | 0 1 7 4


...Diversity: 1.2
...Forced teaching with Sentence: "< 0 6&B 0 | 0 1&2&B 0 | 0 1 0 | 1 4&5 4 >"

...Sentence :  < 0 6&B 0 | 0 1&2&B 0 | 0 1 0 | 1 4&5 4 >
...Generated:  < 2 2 5&1 | 0 1&5 6 > > 0 0&3 > 2&1 7 0


Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1  already exists
Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1/forced/  already exists
Model: "sequential_4"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 embedding_4 (Embedding)     (None, 87, 8)             152

 dropout_8 (Dropout)         (None, 87, 8)             0

 lstm_4 (LSTM)               (None, 64)                18688

 dropout_9 (Dropout)         (None, 64)                0

 dense_4 (Dense)             (None, 19)                1235

=================================================================
Total params: 20,075
Trainable params: 20,075
Non-trainable params: 0
_________________________________________________________________
None

...Diversity: 0.2
...Forced teaching with Sentence: "< 3 1&2 3 | 0 2&7 0 | 2&3 2 0 | 2&3&4&8 2&4&6&8 1&3&8 >"
WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.rho

...Sentence :  < 3 1&2 3 | 0 2&7 0 | 2&3 2 0 | 2&3&4&8 2&4&6&8 1&3&8 >
...Generated:  < 0 1 3 0 | 0 1 4 0 | 0 3 1 0 | 0 2 3 4 1 3 4 3 1 2 4


...Diversity: 0.5
...Forced teaching with Sentence: "< 3 1&2 3 | 0 2&7 0 | 2&3 2 0 | 2&3&4&8 2&4&6&8 1&3&8 >"

...Sentence :  < 3 1&2 3 | 0 2&7 0 | 2&3 2 0 | 2&3&4&8 2&4&6&8 1&3&8 >
...Generated:  < 1&5&2 2 | 1 1 5 0 | 0 2 1 0 | 0 2 4 4 1 9 4 5 0 4&2


...Diversity: 1.0
...Forced teaching with Sentence: "< 3 1&2 3 | 0 2&7 0 | 2&3 2 0 | 2&3&4&8 2&4&6&8 1&3&8 >"

...Sentence :  < 3 1&2 3 | 0 2&7 0 | 2&3 2 0 | 2&3&4&8 2&4&6&8 1&3&8 >
...Generated:  < 1 0&2 0 | 1 0 9 2 > 0&3&7 4 | 3 2 2 9 5& &B 5 >&3 3


...Diversity: 1.2
...Forced teaching with Sentence: "< 3 1&2 3 | 0 2&7 0 | 2&3 2 0 | 2&3&4&8 2&4&6&8 1&3&8 >"

...Sentence :  < 3 1&2 3 | 0 2&7 0 | 2&3 2 0 | 2&3&4&8 2&4&6&8 1&3&8 >
...Generated:  < 3 3&1 2 A 0 842 0 | 6 2 0 4 | 4 3 2&6 3&2 2 3 1&4&2


Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1  already exists
Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1/forced/  already exists
Model: "sequential_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 embedding_5 (Embedding)     (None, 87, 8)             152

 dropout_10 (Dropout)        (None, 87, 8)             0

 lstm_5 (LSTM)               (None, 64)                18688

 dropout_11 (Dropout)        (None, 64)                0

 dense_5 (Dense)             (None, 19)                1235

=================================================================
Total params: 20,075
Trainable params: 20,075
Non-trainable params: 0
_________________________________________________________________
None

...Diversity: 0.2
...Forced teaching with Sentence: "< 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >"
WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.rho

...Sentence :  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >
...Generated:  < 0 2 1&| | 0 0 0 | 0 1 0 4 > 0 1 0


...Diversity: 0.5
...Forced teaching with Sentence: "< 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >"

...Sentence :  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >
...Generated:  < 3 2&1&0 > 0 3 0 | 0 4 4 3 > 0 1 0


...Diversity: 1.0
...Forced teaching with Sentence: "< 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >"

...Sentence :  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >
...Generated:  < 0 6 0&1 | 0 4 7 > 4&4 4 2&> 0 0 2


...Diversity: 1.2
...Forced teaching with Sentence: "< 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >"

...Sentence :  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >
...Generated:  < 2&5 1 > | 3 0 0 | 1&5 0&C | 0 1 0


Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1  already exists
Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1/forced/  already exists
Model: "sequential_6"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 embedding_6 (Embedding)     (None, 87, 8)             152

 dropout_12 (Dropout)        (None, 87, 8)             0

 lstm_6 (LSTM)               (None, 64)                18688

 dropout_13 (Dropout)        (None, 64)                0

 dense_6 (Dense)             (None, 19)                1235

=================================================================
Total params: 20,075
Trainable params: 20,075
Non-trainable params: 0
_________________________________________________________________
None

...Diversity: 0.2
...Forced teaching with Sentence: "< 1&2&3 1 3 | 2&3 1 0 | 2&3 1 0 | 2 1&6 0 >"
WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.rho

...Sentence :  < 1&2&3 1 3 | 2&3 1 0 | 2&3 1 0 | 2 1&6 0 >
...Generated:  < 1 2 3 1 2 | 1 2 1 0 | 0 2 1 2 | 0 1 2 0


...Diversity: 0.5
...Forced teaching with Sentence: "< 1&2&3 1 3 | 2&3 1 0 | 2&3 1 0 | 2 1&6 0 >"

...Sentence :  < 1&2&3 1 3 | 2&3 1 0 | 2&3 1 0 | 2 1&6 0 >
...Generated:  < 0 2 3 0&2 | 4&3 0 1 | 0 3 1 1 | 2 0 4 0


...Diversity: 1.0
...Forced teaching with Sentence: "< 1&2&3 1 3 | 2&3 1 0 | 2&3 1 0 | 2 1&6 0 >"

...Sentence :  < 1&2&3 1 3 | 2&3 1 0 | 2&3 1 0 | 2 1&6 0 >
...Generated:  < 1&3 4 1 1 | 1 2 0&1 | 3 5 2&0 > 0 5 4 4


...Diversity: 1.2
...Forced teaching with Sentence: "< 1&2&3 1 3 | 2&3 1 0 | 2&3 1 0 | 2 1&6 0 >"

...Sentence :  < 1&2&3 1 3 | 2&3 1 0 | 2&3 1 0 | 2 1&6 0 >
...Generated:  < 2&2 9 A&3 > 4 361&0 > 8 3 1 | | 1 1 8 4


Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1  already exists
Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1/seed/  Created
Model: "sequential_7"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 embedding_7 (Embedding)     (None, 87, 8)             152

 dropout_14 (Dropout)        (None, 87, 8)             0

 lstm_7 (LSTM)               (None, 64)                18688

 dropout_15 (Dropout)        (None, 64)                0

 dense_7 (Dense)             (None, 19)                1235

=================================================================
Total params: 20,075
Trainable params: 20,075
Non-trainable params: 0
_________________________________________________________________
None

...Diversity: 0.2
...Generating with seed: "< 1"
...Sentence :  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2 0 >
...Generated:  < 1 1 0 | 0 0 0 | 0 0 0 | 0 0 0 >
...Diversity: 0.5
...Generating with seed: "< 1"
...Sentence :  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2 0 >
...Generated:  < 1&3 1 >
...Diversity: 1.0
...Generating with seed: "< 1"
...Sentence :  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2 0 >
...Generated:  < 1&3 1 | 0 1 0&>
...Diversity: 1.2
...Generating with seed: "< 1"
WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.rho
...Sentence :  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2 0 >
...Generated:  < 1 1&2&2 3 | 0 5 2&5 >
Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1  already exists
Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1/seed/  already exists
Model: "sequential_8"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 embedding_8 (Embedding)     (None, 87, 8)             152

 dropout_16 (Dropout)        (None, 87, 8)             0

 lstm_8 (LSTM)               (None, 64)                18688

 dropout_17 (Dropout)        (None, 64)                0

 dense_8 (Dense)             (None, 19)                1235

=================================================================
Total params: 20,075
Trainable params: 20,075
Non-trainable params: 0
_________________________________________________________________
None

...Diversity: 0.2
...Generating with seed: "< 1&2&4 2&4 4 "
WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.rho
...Sentence :  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2 0 >
...Generated:  < 1&2&4 2&4 4 | 0 1 0 | 0 1 0 | 0 0 0 | 0 0 0 | 0 0 0 | 0 4 0 | 0 1 0 | 0 0 0 | 0 1 0
...Diversity: 0.5
...Generating with seed: "< 1&2&4 2&4 4 "
...Sentence :  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2 0 >
...Generated:  < 1&2&4 2&4 4 | 0 0 0 >
...Diversity: 1.0
...Generating with seed: "< 1&2&4 2&4 4 "
...Sentence :  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2 0 >
...Generated:  < 1&2&4 2&4 4 >
...Diversity: 1.2
...Generating with seed: "< 1&2&4 2&4 4 "
...Sentence :  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2 0 >
...Generated:  < 1&2&4 2&4 4 >
Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1  already exists
Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1/seed/  already exists
Model: "sequential_9"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 embedding_9 (Embedding)     (None, 87, 8)             152

 dropout_18 (Dropout)        (None, 87, 8)             0

 lstm_9 (LSTM)               (None, 64)                18688

 dropout_19 (Dropout)        (None, 64)                0

 dense_9 (Dense)             (None, 19)                1235

=================================================================
Total params: 20,075
Trainable params: 20,075
Non-trainable params: 0
_________________________________________________________________
None

...Diversity: 0.2
...Generating with seed: "< 1&2&4 2&4 4 | 0 1&2"
WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.rho
...Sentence :  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2 0 >
...Generated:  < 1&2&4 2&4 4 | 0 1&2 0 | 0 0 0 | 0 6 0 | 0 1&2 0 | 0 0 0 | 0 0 0 | 0 0 0 | 0 0 0 | 0
...Diversity: 0.5
...Generating with seed: "< 1&2&4 2&4 4 | 0 1&2"
...Sentence :  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2 0 >
...Generated:  < 1&2&4 2&4 4 | 0 1&2 1&5 >
...Diversity: 1.0
...Generating with seed: "< 1&2&4 2&4 4 | 0 1&2"
...Sentence :  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2 0 >
...Generated:  < 1&2&4 2&4 4 | 0 1&2 3&4 | 1&4 5 0 | 0 6 0 >
...Diversity: 1.2
...Generating with seed: "< 1&2&4 2&4 4 | 0 1&2"
...Sentence :  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2 0 >
...Generated:  < 1&2&4 2&4 4 | 0 1&2 1 4 B 4&8 3 0 >
Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1  already exists
Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1/seed/  already exists
Model: "sequential_10"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 embedding_10 (Embedding)    (None, 87, 8)             152

 dropout_20 (Dropout)        (None, 87, 8)             0

 lstm_10 (LSTM)              (None, 64)                18688

 dropout_21 (Dropout)        (None, 64)                0

 dense_10 (Dense)            (None, 19)                1235

=================================================================
Total params: 20,075
Trainable params: 20,075
Non-trainable params: 0
_________________________________________________________________
None

...Diversity: 0.2
...Generating with seed: "< 1&2&4 2&4 4 | 0 1&2 0 | 0 2"
WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.rho
...Sentence :  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2 0 >
...Generated:  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 0 0 | 0 0 0 | 0 0 0 | 0 0 0 | 0 0 0 | 0 0 0 | 0 0
...Diversity: 0.5
...Generating with seed: "< 1&2&4 2&4 4 | 0 1&2 0 | 0 2"
...Sentence :  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2 0 >
...Generated:  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 >
...Diversity: 1.0
...Generating with seed: "< 1&2&4 2&4 4 | 0 1&2 0 | 0 2"
...Sentence :  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2 0 >
...Generated:  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 4 >
...Diversity: 1.2
...Generating with seed: "< 1&2&4 2&4 4 | 0 1&2 0 | 0 2"
...Sentence :  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2 0 >
...Generated:  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2&3 8 | 2&3 1&4 5 | 2&5 2&4 5 >
Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1  already exists
Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1/seed/  already exists
Model: "sequential_11"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 embedding_11 (Embedding)    (None, 87, 8)             152

 dropout_22 (Dropout)        (None, 87, 8)             0

 lstm_11 (LSTM)              (None, 64)                18688

 dropout_23 (Dropout)        (None, 64)                0

 dense_11 (Dense)            (None, 19)                1235

=================================================================
Total params: 20,075
Trainable params: 20,075
Non-trainable params: 0
_________________________________________________________________
None

...Diversity: 0.2
...Generating with seed: "< 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2"
WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.rho
...Sentence :  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2 0 >
...Generated:  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2 0 | 0 0 0 | 0 0 0 | 0 0 0 | 0 0 0 | 0 0 0 | 0
...Diversity: 0.5
...Generating with seed: "< 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2"
...Sentence :  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2 0 >
...Generated:  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2 0 | 0 0 0 | 1&3 3&4 >
...Diversity: 1.0
...Generating with seed: "< 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2"
...Sentence :  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2 0 >
...Generated:  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2&5 4 1 | 0 3 0 | 3 0 0 | 0&3&2 1 >
...Diversity: 1.2
...Generating with seed: "< 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2"
...Sentence :  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2 0 >
...Generated:  < 1&2&4 2&4 4 | 0 1&2 0 | 0 2 0 | 0 1&2&0 6 | 0 0 0 | 0 7 0 >
Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1  already exists
Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1/seed/  already exists
Model: "sequential_12"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 embedding_12 (Embedding)    (None, 87, 8)             152

 dropout_24 (Dropout)        (None, 87, 8)             0

 lstm_12 (LSTM)              (None, 64)                18688

 dropout_25 (Dropout)        (None, 64)                0

 dense_12 (Dense)            (None, 19)                1235

=================================================================
Total params: 20,075
Trainable params: 20,075
Non-trainable params: 0
_________________________________________________________________
None

...Diversity: 0.2
...Generating with seed: "< 3&5 1"
WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.rho
...Sentence :  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >
...Generated:  < 3&5 1 0 | 0 1 0 | 0 0 0 | 0 0 0 | 0 0 0 | 0 0 0 | 0 1 0 | 0 1 0 | 0 0 0 >
...Diversity: 0.5
...Generating with seed: "< 3&5 1"
...Sentence :  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >
...Generated:  < 3&5 1 0 | 0 2 0 | 0 0 0 >
...Diversity: 1.0
...Generating with seed: "< 3&5 1"
...Sentence :  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >
...Generated:  < 3&5 1 5 | 0 1&5&4 2 2&3 | 0 6 0 | 0 4 6 | 2 4 2&8 | 0 4 0 >
...Diversity: 1.2
...Generating with seed: "< 3&5 1"
...Sentence :  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >
...Generated:  < 3&5 1&A&C 4 0 |>
Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1  already exists
Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1/seed/  already exists
Model: "sequential_13"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 embedding_13 (Embedding)    (None, 87, 8)             152

 dropout_26 (Dropout)        (None, 87, 8)             0

 lstm_13 (LSTM)              (None, 64)                18688

 dropout_27 (Dropout)        (None, 64)                0

 dense_13 (Dense)            (None, 19)                1235

=================================================================
Total params: 20,075
Trainable params: 20,075
Non-trainable params: 0
_________________________________________________________________
None

...Diversity: 0.2
...Generating with seed: "< 3&5 1 3 |"
WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.rho
...Sentence :  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >
...Generated:  < 3&5 1 3 | 0 0 0 | 0 0 0 | 0 0 0 | 0 0 0 | 0 1 0 | 0 0 0 | 0 0 0 | 0 0 0 | 0 1 0 | 0
...Diversity: 0.5
...Generating with seed: "< 3&5 1 3 |"
...Sentence :  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >
...Generated:  < 3&5 1 3 | 1 2 2 | 0 1 1&2 >
...Diversity: 1.0
...Generating with seed: "< 3&5 1 3 |"
...Sentence :  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >
...Generated:  < 3&5 1 3 | 0 4 0 | 1&5 1 4 >
...Diversity: 1.2
...Generating with seed: "< 3&5 1 3 |"
...Sentence :  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >
...Generated:  < 3&5 1 3 | 0 0&&52 >
Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1  already exists
Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1/seed/  already exists
Model: "sequential_14"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 embedding_14 (Embedding)    (None, 87, 8)             152

 dropout_28 (Dropout)        (None, 87, 8)             0

 lstm_14 (LSTM)              (None, 64)                18688

 dropout_29 (Dropout)        (None, 64)                0

 dense_14 (Dense)            (None, 19)                1235

=================================================================
Total params: 20,075
Trainable params: 20,075
Non-trainable params: 0
_________________________________________________________________
None

...Diversity: 0.2
...Generating with seed: "< 3&5 1 3 | 0 0 0"
WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.rho
...Sentence :  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >
...Generated:  < 3&5 1 3 | 0 0 0 | 0 4 0 | 0 0 0 | 0 0 0 | 0 0 0 | 0 0 0 | 0 0 0 | 0 0 0 | 0 0 0 | 0
...Diversity: 0.5
...Generating with seed: "< 3&5 1 3 | 0 0 0"
...Sentence :  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >
...Generated:  < 3&5 1 3 | 0 0 0 | 0 1 0 | 0 4 0 | 1 1&2 >
...Diversity: 1.0
...Generating with seed: "< 3&5 1 3 | 0 0 0"
...Sentence :  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >
...Generated:  < 3&5 1 3 | 0 0 0 | 0 1&2 0 | 0 4 0&7 0 1 3 | 3&3 4 1&6 >
...Diversity: 1.2
...Generating with seed: "< 3&5 1 3 | 0 0 0"
...Sentence :  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >
...Generated:  < 3&5 1 3 | 0 0 0 >
Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1  already exists
Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1/seed/  already exists
Model: "sequential_15"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 embedding_15 (Embedding)    (None, 87, 8)             152

 dropout_30 (Dropout)        (None, 87, 8)             0

 lstm_15 (LSTM)              (None, 64)                18688

 dropout_31 (Dropout)        (None, 64)                0

 dense_15 (Dense)            (None, 19)                1235

=================================================================
Total params: 20,075
Trainable params: 20,075
Non-trainable params: 0
_________________________________________________________________
None

...Diversity: 0.2
...Generating with seed: "< 3&5 1 3 | 0 0 0 | 2 0 2&3"
WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.rho
...Sentence :  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >
...Generated:  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 3 1 0 | 0 0 0 | 0 4 0 | 0 1 0 | 0 1 0 | 0 0 0 | 0 0 0 |
...Diversity: 0.5
...Generating with seed: "< 3&5 1 3 | 0 0 0 | 2 0 2&3"
...Sentence :  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >
...Generated:  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 0 0 0 | 0 0 0 >
...Diversity: 1.0
...Generating with seed: "< 3&5 1 3 | 0 0 0 | 2 0 2&3"
...Sentence :  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >
...Generated:  < 3&5 1 3 | 0 0 0 | 2 0 2&3 >
...Diversity: 1.2
...Generating with seed: "< 3&5 1 3 | 0 0 0 | 2 0 2&3"
...Sentence :  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >
...Generated:  < 3&5 1 3 | 0 0 0 | 2 0 2&3 >
Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1  already exists
Directory  /Users/davis/PycharmProjects/LmForGuiGeneration/gui2lm/gui2lm/language_model/text_generations/V_Test1/seed/  already exists
Model: "sequential_16"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 embedding_16 (Embedding)    (None, 87, 8)             152

 dropout_32 (Dropout)        (None, 87, 8)             0

 lstm_16 (LSTM)              (None, 64)                18688

 dropout_33 (Dropout)        (None, 64)                0

 dense_16 (Dense)            (None, 19)                1235

=================================================================
Total params: 20,075
Trainable params: 20,075
Non-trainable params: 0
_________________________________________________________________
None

...Diversity: 0.2
...Generating with seed: "< 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6"
...Sentence :  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >
...Generated:  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 | 0 1 0 | 0 1 0 >
...Diversity: 0.5
...Generating with seed: "< 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6"
...Sentence :  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >
...Generated:  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >
...Diversity: 1.0
...Generating with seed: "< 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6"
WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.rho
...Sentence :  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >
...Generated:  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6&7 2&4 | 0 1&7 4 | 0 1 0 | 0 6 0 | 1 5 0 >
...Diversity: 1.2
...Generating with seed: "< 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6"
...Sentence :  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 0 >
...Generated:  < 3&5 1 3 | 0 0 0 | 2 0 2&3 | 2 6 1&3 >
